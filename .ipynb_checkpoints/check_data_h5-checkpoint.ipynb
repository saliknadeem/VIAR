{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import random\n",
    "import operator\n",
    "import collections\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import cv2\n",
    "import skimage.measure\n",
    "from skimage.transform import resize\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '~/ExtractedFlowH5_test/S008C001P001R001A001_3dflow.h5', errno = 2, error message = 'No such file or directory', flags = 40, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ad4ea5eb82f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mflow_h5_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_h5_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideoname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_3dflow.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mflow_h5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow_h5_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#####flows = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mflowsActual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/action/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/action/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '~/ExtractedFlowH5_test/S008C001P001R001A001_3dflow.h5', errno = 2, error message = 'No such file or directory', flags = 40, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "flow_h5_dir = '~/ExtractedFlowH5_test/'\n",
    "videoname = 'S008C001P001R001A001'\n",
    "#frame_indices = [0,1,2,3,4,5]\n",
    "\n",
    "flow_h5_path = os.path.join(flow_h5_dir, videoname + '_3dflow.h5')\n",
    "flow_h5 = h5py.File(flow_h5_path, 'r', libver='latest', swmr=True)\n",
    "#####flows = []\n",
    "flowsActual = []\n",
    "for f in flow_h5['flow']:\n",
    "    #flow = cropND(f, (self.side_size // self.patch_size, self.side_size // self.patch_size, 3)) # centercrop\n",
    "    #flow = skimage.measure.block_reduce(f, (8,8), np.mean)\n",
    "    flowActual = torch.from_numpy(f)\n",
    "    #flowActual = cropND(flowActual, (self.side_size, self.side_size, 3))\n",
    "    #flowActual = resize(flowActual, (224, 224))\n",
    "    flowActual = np.transpose(flowActual, (2,0,1)) \n",
    "    flowActual[flowActual <0.005] = 0\n",
    "    flowActual = flowActual * 50\n",
    "    #flowActual = self.flow_transform(flowActual)\n",
    "    #flow = torch.from_numpy(f)\n",
    "\n",
    "\n",
    "    ##### Resize operation using interpolate on tensors\n",
    "    #'''flow = np.transpose(flow, (2, 0, 1))\n",
    "    #flow = F.interpolate(flow, self.side_size // self.patch_size)\n",
    "    #flow = np.transpose(flow, (2, 0, 1))\n",
    "    #flow = F.interpolate(flow, self.side_size // self.patch_size)\n",
    "    #flow = np.transpose(flow, (1,0,2))'''\n",
    "    ######################\n",
    "    #####flow = np.transpose(flow, (2,0,1))\n",
    "\n",
    "    #flowActual[flowActual != 0] = flowActual[flowActual != 0] + 3.1465\n",
    "    ##flowActual = flowActual + 3.1465\n",
    "    #####flow = flow * 1000 # multiply 50 to \"keep proper scale\" according to [1]\n",
    "    flowsActual.append(torch.FloatTensor(flowActual))\n",
    "    #####flows.append(torch.FloatTensor(flow))\n",
    "#####flows = torch.stack(flows)\n",
    "flowsActual = torch.stack(flowsActual)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98, 3, 224, 224])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowsActual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "#import imageio\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plot images as an animated video\n",
    "import matplotlib.animation as animation\n",
    "#%matplotlib inline\n",
    "\n",
    "def visualize_3dflow(flowsActual,out_folder_vis):\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ims=[]\n",
    "    images = []\n",
    "\n",
    "    for flow in flowsActual:\n",
    "        img = np.transpose(flow.numpy(), (1,2,0))\n",
    "        #img = cv.imread(paths,cv.IMREAD_COLOR)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        #print(np.shape(img))\n",
    "        im = plt.imshow(img, animated=True)\n",
    "        ims.append([im])\n",
    "    \n",
    "    print(np.shape(ims))\n",
    "    print(str(np.shape(img)))\n",
    "\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=41, blit=True,\n",
    "                                   repeat_delay=1000,repeat=True)\n",
    "    #ani.save(out_folder_vis)\n",
    "\n",
    "    \n",
    "    writergif = animation.PillowWriter(fps=30) \n",
    "    ani.save(out_folder_vis, writer=writergif)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 1)\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"fig = plt.figure(figsize=(15,10))\n",
    "plt.imshow(np.transpose(flowsActual[5], (1,2,0)), interpolation='nearest')\n",
    "plt.show()\"\"\"\n",
    "\n",
    "out_folder_vis = videoname+'.gif'\n",
    "visualize_3dflow(flowsActual,out_folder_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
